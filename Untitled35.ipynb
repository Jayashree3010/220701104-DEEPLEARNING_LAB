# Ex No: 7 Build Autoencoders with Keras/TensorFlow

# Step 1: Import Libraries
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Flatten, Reshape
from tensorflow.keras.datasets import mnist
import matplotlib.pyplot as plt
import numpy as np

# Step 2: Load Dataset (MNIST digits)
(x_train, _), (x_test, _) = mnist.load_data()

# Normalize data (0-1 range) and flatten
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0
x_train = x_train.reshape((len(x_train), 28*28))
x_test = x_test.reshape((len(x_test), 28*28))

# Step 3: Build Autoencoder Model
input_dim = 784  # 28x28 images flattened
encoding_dim = 64  # size of compressed representation

# Input layer
input_img = Input(shape=(input_dim,))

# Encoder
encoded = Dense(128, activation='relu')(input_img)
encoded = Dense(encoding_dim, activation='relu')(encoded)

# Decoder
decoded = Dense(128, activation='relu')(encoded)
decoded = Dense(input_dim, activation='sigmoid')(decoded)

# Autoencoder model
autoencoder = Model(input_img, decoded)

# Step 4: Compile Model
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# Step 5: Train Model
history = autoencoder.fit(
    x_train, x_train,
    epochs=10,
    batch_size=256,
    shuffle=True,
    validation_data=(x_test, x_test)
)

# Step 6: Predictions (Reconstruction)
decoded_imgs = autoencoder.predict(x_test)

# Step 7: Visualization (Original vs Reconstructed)
n = 10  # show 10 images
plt.figure(figsize=(20, 4))
for i in range(n):
    # Original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(28, 28), cmap="gray")
    plt.title("Original")
    plt.axis("off")

    # Reconstructed
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap="gray")
    plt.title("Reconstructed")
    plt.axis("off")
plt.show()

# Step 8: Performance Metric (Reconstruction Loss)
loss = autoencoder.evaluate(x_test, x_test, verbose=0)
print(f"Reconstruction Loss: {loss:.4f}")
